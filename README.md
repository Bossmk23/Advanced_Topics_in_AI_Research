#  Advanced Topics in AI Research: Generative Models

This repository contains the complete deliverables for our project on **Generative Models**, completed as part of the _Advanced Topics in AI Research_ course. Our focus was on implementing, analyzing, and comparing **Variational Autoencoders (VAEs)** and **Generative Adversarial Networks (GANs)**, while exploring common challenges such as loss functions, training instability, and mode collapse.

---

##  Topics Covered

- **Variational Autoencoders (VAEs)**  
- **Generative Adversarial Networks (GANs)**  
- **Training dynamics and stability**  
- **Loss function behaviors (ELBO, BCE, Wasserstein)**  
- **Regularization techniques** (Dropout, Spectral Normalization, Gradient Penalty, etc.)

---

##  Hands-On Tasks

-  Implemented VAE and GAN models using PyTorch and TensorFlow  
-  Experimented with BCE and Wasserstein loss  
-  Applied regularization methods to stabilize GANs  
-  Trained models on MNIST and Fashion MNIST datasets  
-  Visualized outputs, latent space embeddings, and loss curves

---

##  Deliverables

| Type            | Description                                         | File(s)                                                                 |
|-----------------|-----------------------------------------------------|-------------------------------------------------------------------------|
|  Report        | Full research report with theory, implementation, results | `Research Report.docx` / `Formatted_Research_Report.docx`               |
|  Presentation | Summary of findings, visuals, and comparisons       | `Generative Adversarial Networks Ppt task.pptx` / Redesigned version    |
|  Code         | Jupyter Notebooks for VAE, GAN, and regularization  | `code`|
|  Blog  | Contains a deep explained code blog              | `generative_models_comprehensive_guide.markdown`                                          |

---

##  Key Insights

- VAEs offer strong **latent space control** but less visual clarity  
- GANs deliver **photo-realistic results**, yet require tuning and stability tricks  
- Techniques like **spectral normalization** and **gradient penalty** greatly improve GAN behavior  
- Combining VAE and GAN principles (e.g., VAE-GAN) presents exciting future opportunities

---

##  Future Work

Explore advanced models such as:
- **Diffusion Models**
- **Transformer-based generators**
- **VAE-GAN hybrids**
- Real-world applications in **design, healthcare, and content generation**

---

##  Authors

- Manika Singh  
- Seema Verma  
- Sabha Ambrin  
- Gaurav Singh Parihar

---

##  Tools Used

- Python, PyTorch, TensorFlow  
- Jupyter Notebooks  
- Canva (for presentation design)  
- GitHub (for version control and collaboration)

---

> _“From unstable training to high-quality generation — our journey with generative AI begins.”_


